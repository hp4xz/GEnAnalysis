{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f23814d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.26/06\n"
     ]
    }
   ],
   "source": [
    "import ROOT as r\n",
    "import math\n",
    "import array\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import uproot\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "#______________Add include directory_______________\n",
    "current_dir = os.getcwd()\n",
    "include_dir = os.path.join(current_dir, 'include')\n",
    "sys.path.insert(0, include_dir)\n",
    "#__________________________________________________\n",
    "\n",
    "import CONFIG\n",
    "import DBPARSE\n",
    "from UTILITIES import *\n",
    "from SIMFITS2D import DistributionFits2D\n",
    "from ROOT import gStyle, TChain, TH1F, TCanvas, TLegend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b2e187c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "GEN2Pathp1=f\"/media/research/TOSHIBA EXT/GEn/outfiles/pass1/Pass1_data_GEN2_sbs100p_nucleon_np_model2.root\"\n",
    "GEN3Pathp1=f\"/media/research/TOSHIBA EXT/GEn/outfiles/pass1/Pass1_data_GEN3_sbs100p_nucleon_np_model2.root\"\n",
    "GEN4aPathp1=f\"/media/research/TOSHIBA EXT/GEn/outfiles/pass1/Pass1_data_GEN4a_sbs100p_nucleon_np_model2.root\"\n",
    "GEN4bPathp1=f\"/media/research/TOSHIBA EXT/GEn/outfiles/pass1/Pass1_data_GEN4b_sbs100p_nucleon_np_model2.root\"\n",
    "\n",
    "\n",
    "\n",
    "GEN2Pathp2=f\"/media/research/TOSHIBA EXT/GEn/outfiles/pass2/Pass2_data_GEN2_sbs100p_nucleon_np_model2.root\"\n",
    "GEN3Pathp2=f\"/media/research/TOSHIBA EXT/GEn/outfiles/pass2/Pass2_data_GEN3_sbs100p_nucleon_np_model2.root\"\n",
    "GEN4aPathp2=f\"/media/research/TOSHIBA EXT/GEn/outfiles/pass2/Pass2_data_GEN4a_sbs100p_nucleon_np_model2.root\"\n",
    "GEN4bPathp2=f\"/media/research/TOSHIBA EXT/GEn/outfiles/pass2/Pass2_data_GEN4b_sbs100p_nucleon_np_model2.root\"\n",
    "\n",
    "GEN3PathTiming=f\"/media/research/TOSHIBA EXT/GEn/outfiles/pass2/Pass2_timing_GEN3_sbs100p_nucleon_np_model2.root\"\n",
    "GEN2PathTiming=f\"/media/research/TOSHIBA EXT/GEn/outfiles/pass2/Pass2_timing2_GEN2_sbs100p_nucleon_np_model2.root\"\n",
    "\n",
    "GEN3InSim=f\"/media/research/TOSHIBA EXT/GEn/outfiles/insim/QE_Insim_GEN3_sbs100p_nucleon_np_model2.root\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f41ae50",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Branches in tree 'Tout':\n",
      "WCut\n",
      "pCut\n",
      "nCut\n",
      "weight\n",
      "mc_Aperp1\n",
      "mc_sig\n",
      "mc_sigOld\n",
      "mc_sigPol\n",
      "mc_BETA\n",
      "mc_THETA\n",
      "fnucl\n",
      "fiduCut\n",
      "coinCut\n",
      "ebeam\n",
      "nu\n",
      "Q2\n",
      "W2\n",
      "dpel\n",
      "ephi\n",
      "etheta\n",
      "pcentral\n",
      "vz\n",
      "vx\n",
      "vy\n",
      "xtgt\n",
      "ytgt\n",
      "thtgt\n",
      "phtgt\n",
      "xfp\n",
      "yfp\n",
      "thfp\n",
      "phfp\n",
      "trP\n",
      "trPx\n",
      "trPy\n",
      "trPz\n",
      "trX\n",
      "trY\n",
      "trTh\n",
      "trPh\n",
      "ePS\n",
      "eSH\n",
      "eHCAL\n",
      "xHCAL\n",
      "yHCAL\n",
      "xHCAL_exp\n",
      "yHCAL_exp\n",
      "dx\n",
      "dy\n",
      "grinch_track\n",
      "grinch_clus_size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in <TList::Clear>: A list is accessing an object (0x3b1eb9a0) already deleted (list name = TList)\n",
      "Error in <TList::Clear>: A list is accessing an object (0x3ba2bab0) already deleted (list name = TList)\n",
      "Error in <TList::Clear>: A list is accessing an object (0x3ba2bee0) already deleted (list name = TList)\n",
      "Error in <TList::Clear>: A list is accessing an object (0x3ba109d0) already deleted (list name = TList)\n",
      "Error in <TList::Clear>: A list is accessing an object (0x3ba10d40) already deleted (list name = TList)\n",
      "Error in <TList::Clear>: A list is accessing an object (0x3ba110b0) already deleted (list name = TList)\n",
      "Error in <TList::Clear>: A list is accessing an object (0x3ba115e0) already deleted (list name = TList)\n",
      "Error in <TList::Clear>: A list is accessing an object (0x3ba119a0) already deleted (list name = TList)\n",
      "Error in <TList::Clear>: A list is accessing an object (0x3ba12300) already deleted (list name = TList)\n",
      "Error in <TList::Clear>: A list is accessing an object (0x3ba126f0) already deleted (list name = TList)\n",
      "Error in <TList::Clear>: A list is accessing an object (0x3ba12df0) already deleted (list name = TList)\n",
      "Error in <TList::Clear>: A list is accessing an object (0x3ba131e0) already deleted (list name = TList)\n",
      "Error in <TList::Clear>: A list is accessing an object (0x3ba135a0) already deleted (list name = TList)\n",
      "Error in <TList::Clear>: A list is accessing an object (0x3ba93220) already deleted (list name = TList)\n",
      "Error in <TList::Clear>: A list is accessing an object (0x3ba937e0) already deleted (list name = TList)\n",
      "Error in <TList::Clear>: A list is accessing an object (0x3ba93c10) already deleted (list name = TList)\n",
      "Error in <TList::Clear>: A list is accessing an object (0x3bab16d0) already deleted (list name = TList)\n",
      "Error in <TList::Clear>: A list is accessing an object (0x3bab8cc0) already deleted (list name = TList)\n",
      "Error in <TList::Clear>: A list is accessing an object (0x3bab9040) already deleted (list name = TList)\n",
      "Error in <TList::Clear>: A list is accessing an object (0x3bab94e0) already deleted (list name = TList)\n",
      "Error in <TList::Clear>: A list is accessing an object (0x3babad20) already deleted (list name = TList)\n",
      "Error in <TList::Clear>: A list is accessing an object (0x3babb230) already deleted (list name = TList)\n",
      "Error in <TList::Clear>: A list is accessing an object (0x3babbcb0) already deleted (list name = TList)\n",
      "Error in <TList::Clear>: A list is accessing an object (0x3babbee0) already deleted (list name = TList)\n",
      "Error in <TList::Clear>: A list is accessing an object (0x3babc340) already deleted (list name = TList)\n",
      "Error in <TList::Clear>: A list is accessing an object (0x3babd340) already deleted (list name = TList)\n",
      "Error in <TList::Clear>: A list is accessing an object (0x3bac6890) already deleted (list name = TList)\n",
      "Error in <TList::Clear>: A list is accessing an object (0x3bac86f0) already deleted (list name = TList)\n",
      "Error in <TList::Clear>: A list is accessing an object (0x3bac9580) already deleted (list name = TList)\n",
      "Error in <TList::Clear>: A list is accessing an object (0x3baca230) already deleted (list name = TList)\n",
      "Error in <TList::Clear>: A list is accessing an object (0x3baca970) already deleted (list name = TList)\n",
      "Error in <TList::Clear>: A list is accessing an object (0x3bacae20) already deleted (list name = TList)\n",
      "Error in <TList::Clear>: A list is accessing an object (0x3bacb150) already deleted (list name = TList)\n",
      "Error in <TList::Clear>: A list is accessing an object (0x3bacb6f0) already deleted (list name = TList)\n",
      "Error in <TList::Clear>: A list is accessing an object (0x3bacbbe0) already deleted (list name = TList)\n",
      "Error in <TList::Clear>: A list is accessing an object (0x3bad0110) already deleted (list name = TList)\n",
      "Error in <TList::Clear>: A list is accessing an object (0x3bad08a0) already deleted (list name = TList)\n",
      "Error in <TList::Clear>: A list is accessing an object (0x3bad1c40) already deleted (list name = TList)\n",
      "Error in <TList::Clear>: A list is accessing an object (0x3bad1de0) already deleted (list name = TList)\n",
      "Error in <TList::Clear>: A list is accessing an object (0x3bad2260) already deleted (list name = TList)\n",
      "Error in <TList::Clear>: A list is accessing an object (0x3bad3000) already deleted (list name = TList)\n",
      "Error in <TList::Clear>: A list is accessing an object (0x3bad3480) already deleted (list name = TList)\n",
      "Error in <TList::Clear>: A list is accessing an object (0x3ba26d80) already deleted (list name = TList)\n",
      "Error in <TList::Clear>: A list is accessing an object (0x3ba276f0) already deleted (list name = TList)\n",
      "Error in <THashList::Delete>: A list is accessing an object (0x3b72d7c0) already deleted (list name = THashList)\n"
     ]
    }
   ],
   "source": [
    "#available branches\n",
    "import ROOT as r\n",
    "\n",
    "\n",
    "def list_branches(rootfile_path, tree_name=\"Tout\"):\n",
    "    # Open the ROOT file\n",
    "    root_file = r.TFile.Open(rootfile_path)\n",
    "    \n",
    "    # Check if the file was successfully opened\n",
    "    if not root_file or root_file.IsZombie():\n",
    "        print(f\"Error: Could not open ROOT file '{rootfile_path}'.\")\n",
    "        return\n",
    "    \n",
    "    # Access the TTree\n",
    "    tree = root_file.Get(tree_name)\n",
    "    \n",
    "    # Check if the tree exists\n",
    "    if not tree:\n",
    "        print(f\"Error: Tree '{tree_name}' not found in file '{rootfile_path}'.\")\n",
    "        root_file.Close()\n",
    "        return\n",
    "    \n",
    "    # Get the list of branches\n",
    "    branch_list = tree.GetListOfBranches()\n",
    "    \n",
    "    # Print all branch names\n",
    "    print(f\"Branches in tree '{tree_name}':\")\n",
    "    for branch in branch_list:\n",
    "        print(branch.GetName())\n",
    "    \n",
    "    # Close the ROOT file\n",
    "    root_file.Close()\n",
    "\n",
    "# Example usage\n",
    "list_branches(GEN3InSim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3680e601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#inputs hodo\\nconfig=\"3\"\\nprefix=\"HCal_data\"\\ndetector=\"hodo\"\\n#inputs hcal\\nconfig=\"3\"\\nprefix=\"HCal_data\"\\ndetector=\"hcal\"\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#inputs hodo\n",
    "config=\"3\"\n",
    "prefix=\"HCal_data\"\n",
    "detector=\"hodo\"\n",
    "#inputs hcal\n",
    "config=\"3\"\n",
    "prefix=\"HCal_data\"\n",
    "detector=\"hcal\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fedb294",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define branches\n",
    "branches=[\"ebeam\",\"nu\",\"Q2\",\"W2\",\"dpel\",\"ephi\",\"etheta\",\"pcentral\",\"vz\",\"vx\"\n",
    "          ,\"vy\",\"xtgt\",\"ytgt\",\"thtgt\",\"phtgt\",\"thetabend\",\"xfp\",\"yfp\",\"thfp\"\n",
    "          ,\"phfp\",\"trP\",\"trPx\",\"trPy\",\"trPz\",\"ePS\",\"xPS\",\"eSH\",\"xSH\",\"ySH\",\"eHCAL\"\n",
    "          ,\"xHCAL\",\"yHCAL\",\"xHCAL_exp\",\"yHCAL_exp\",\"dx\",\"dy\",\"ngrinch_hits\",\"xGRINCH\"\n",
    "          ,\"yGRINCH\",\"coin_time\",\"hcal_time\",\"bbcal_time\",\"BPMAx\",\"BPMAy\",\"Rasterx\"\n",
    "          ,\"Rastery\",\"Raster2x\",\"Raster2y\",\"helicity\",\"IHWP\",\"pblkid\",\"tdc\",\"atime\"\n",
    "          ,\"nblk\",\"mag\",\"runnum\",\"tar\",\"cblkid\",\"cblkatime\",\"cblktime\",\"cblke\",\"nclus\"\n",
    "          ,\"cid\",\"cx\",\"cy\",\"catime\",\"hodoTimes\",\"hodoIDs\",\"hodoTOT\",\"nbars\"]\n",
    "hodo_branches=[\"hodoTimes\",\"hodoIDs\",\"hodoTOT\",\"nbars\",\"hodoClusMean\"]\n",
    "hcal_branches=[\"cblkid\",\"cblkatime\",\"cblktime\",\"cblke\",\"nclus\"\n",
    "          ,\"cid\",\"cx\",\"cy\",\"catime\"]\n",
    "trigger_branches=[\"trigger\",\"triggerID\",\"NdataTriggerID\"]\n",
    "generic_branches=[\"nu\",\"Q2\",\"W2\",\"vz\",\"vx\",\"vy\",\"dx\",\"dy\",\"eSH\",\"ePS\",\"etheta\",\"ephi\",\"trP\",\"thtgt\",\"phtgt\",\n",
    "                  \"coin_time\",\"trPx\",\"trPy\",\"trPz\",\"ephi\",\"ebeam\",\"helicity\",\"IHWP\",\"runnum\"]\n",
    "generic_branchesp2=[\"nu\",\"Q2\",\"W2\",\"vz\",\"vx\",\"vy\",\"dx\",\"dy\",\"eSH\",\"ePS\",\"etheta\",\"ephi\",\"trP\",\"thtgt\",\"phtgt\",\n",
    "                  \"coin_time\",\"trPx\",\"trPy\",\"trPz\",\"ephi\",\"ebeam\",\"helicity\",\"IHWP\",\"runnum\",\"BBgr_clus_size\",\n",
    "                   \"BBgr_clus_trackindex\"]\n",
    "sim_branches=[\"nu\",\"Q2\",\"W2\",\"vz\",\"vx\",\"vy\",\"dx\",\"dy\",\"eSH\",\"ePS\",\"etheta\",\"ephi\",\"trP\",\"fnucl\",\"weight\"]\n",
    "insim_branches=[\"nu\",\"Q2\",\"W2\",\"vz\",\"vx\",\"vy\",\"dx\",\"dy\",\"eSH\",\"ePS\",\"etheta\",\"trP\",\"fnucl\",\"weight\",\"mc_sig\",\n",
    "               \"mc_sigOld\",\n",
    "               \"mc_sigPol\",\n",
    "               \"mc_BETA\",\n",
    "               \"mc_THETA\"]\n",
    "\n",
    "\n",
    "ml_branches = [\n",
    "    \"ebeam\", \"nu\", \"Q2\", \"W2\", \"dpel\", \"ephi\", \"etheta\", \"pcentral\", \"vz\", \"vx\", \"vy\",\n",
    "    \"xtgt\", \"ytgt\", \"thtgt\", \"phtgt\", \"xfp\", \"yfp\", \"thfp\", \"phfp\", \"trP\",\n",
    "    \"ePS\", \"eSH\", \"eHCAL\", \"xHCAL\", \"yHCAL\", \"xHCAL_exp\", \"yHCAL_exp\",\n",
    "    \"dx\", \"dy\"\n",
    "]\n",
    "tofcal_branches = [\n",
    "    \"tleft\",\n",
    "    \"tright\",\n",
    "    \"totleft\",\n",
    "    \"totright\",\n",
    "    \"vpos\",\n",
    "    \"barid\",\n",
    "    \"nbars\",\n",
    "    \"bb_rftime\",\n",
    "    \"sbs_rftime\",\n",
    "    \"bbtrigtime\",\n",
    "    \"sbstrigtime\",\n",
    "    \"tdctimeblk\",\n",
    "    \"eblk\",\n",
    "    \"idblk\",\n",
    "    \"vz\",\n",
    "    \"xHCAL\",\n",
    "    \"yHCAL\",\n",
    "    \"xSH\",\n",
    "    \"ySH\",\n",
    "    \"pathl\",\n",
    "    \"tr_y\",\n",
    "    \"tr_x\",\n",
    "    \"tr_th\",\n",
    "    \"tr_ph\",\n",
    "    \"HODOtmean\",\n",
    "    \"HCALtw\",\n",
    "    \"W2\",\n",
    "    \"dx\",\n",
    "    \"dy\",\n",
    "    \"trPx\",\n",
    "    \"trPy\",\n",
    "    \"trPz\",\n",
    "    \"trP\",\n",
    "    \"cblkid\",\n",
    "    \"nblk\",\n",
    "    \"cblke\",\n",
    "    \"cblktime\",\n",
    "    \"pN_expected\",\n",
    "    \"npathl\"\n",
    "    \n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15b7d3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ConvertToNP(branches,config,prefix,detector,File,Pass):\n",
    "    # Open the ROOT file\n",
    "    with uproot.open(File) as file:\n",
    "        # Access the tree (replace 'Tout' with the actual name of your tree if different)\n",
    "        tree = file[\"Tout\"]\n",
    "\n",
    "        # Get all branch names\n",
    "        #branches = tree.keys()\n",
    "\n",
    "        chunk_size = 2000000  # Define the chunk size\n",
    "        total_entries = tree.num_entries  # Get the total number of entries\n",
    "        print(total_entries)\n",
    "        total_iterations = total_entries // chunk_size + (total_entries % chunk_size > 0)\n",
    "\n",
    "        for j in range(total_iterations):\n",
    "            print(f\"Processing Chunk {j+1} out of {total_iterations}\")\n",
    "\n",
    "            start = j * chunk_size\n",
    "            stop = min((j + 1) * chunk_size, total_entries)\n",
    "\n",
    "            # Read data for this chunk\n",
    "            data = tree.arrays(branches, entry_start=start, entry_stop=stop, library=\"np\")\n",
    "            \n",
    "            # Save all the branches as a dictionary to .npz\n",
    "            np.savez(f\"/media/research/TOSHIBA EXT/GEn/NumpyData/Pass{Pass}/GEN{config}/{prefix}/{detector}{j}.npz\", **data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0f5beb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08c88a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvertToNPSim(branches,config,detector):\n",
    "    # Open the ROOT file\n",
    "    with uproot.open(f\"/media/research/TOSHIBA EXT/GEn/outfiles/sim/QE_sim_GEN{config}_sbs100p_nucleon_np_model2.root\") as file:\n",
    "        # Access the tree (replace 'Tout' with the actual name of your tree if different)\n",
    "        tree = file[\"Tout\"]\n",
    "\n",
    "        # Get all branch names\n",
    "        #branches = tree.keys()\n",
    "\n",
    "        chunk_size = 2000000  # Define the chunk size\n",
    "        total_entries = tree.num_entries  # Get the total number of entries\n",
    "        total_iterations = total_entries // chunk_size + (total_entries % chunk_size > 0)\n",
    "        print(total_entries)\n",
    "        for j in range(total_iterations):\n",
    "            print(f\"Processing Chunk {j+1} out of {total_iterations}\")\n",
    "\n",
    "            start = j * chunk_size\n",
    "            stop = min((j + 1) * chunk_size, total_entries)\n",
    "\n",
    "            # Read data for this chunk\n",
    "            data = tree.arrays(branches, entry_start=start, entry_stop=stop, library=\"np\")\n",
    "\n",
    "            # Save all the branches as a dictionary to .npz\n",
    "            np.savez(f\"/media/research/TOSHIBA EXT/GEn/NumpySim/GEN{config}/{detector}{j}.npz\", **data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900ce799",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42eec1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvertToNPInSim(branches,config,prefix,detector,File):\n",
    "    # Open the ROOT file\n",
    "    with uproot.open(File) as file:\n",
    "        # Access the tree (replace 'Tout' with the actual name of your tree if different)\n",
    "        tree = file[\"Tout\"]\n",
    "\n",
    "        # Get all branch names\n",
    "        #branches = tree.keys()\n",
    "\n",
    "        chunk_size = 2000000  # Define the chunk size\n",
    "        total_entries = tree.num_entries  # Get the total number of entries\n",
    "        total_iterations = total_entries // chunk_size + (total_entries % chunk_size > 0)\n",
    "        print(total_entries)\n",
    "        for j in range(total_iterations):\n",
    "            print(f\"Processing Chunk {j+1} out of {total_iterations}\")\n",
    "\n",
    "            start = j * chunk_size\n",
    "            stop = min((j + 1) * chunk_size, total_entries)\n",
    "\n",
    "            # Read data for this chunk\n",
    "            data = tree.arrays(branches, entry_start=start, entry_stop=stop, library=\"np\")\n",
    "\n",
    "            # Save all the branches as a dictionary to .npz\n",
    "            np.savez(f\"/media/research/TOSHIBA EXT/GEn/NumpySim/GEN{config}/{detector}{j}.npz\", **data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8314350f",
   "metadata": {},
   "source": [
    "# TIMING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7407e6e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16774692\n",
      "Processing Chunk 1 out of 9\n",
      "Processing Chunk 2 out of 9\n",
      "Processing Chunk 3 out of 9\n",
      "Processing Chunk 4 out of 9\n",
      "Processing Chunk 5 out of 9\n",
      "Processing Chunk 6 out of 9\n",
      "Processing Chunk 7 out of 9\n",
      "Processing Chunk 8 out of 9\n",
      "Processing Chunk 9 out of 9\n"
     ]
    }
   ],
   "source": [
    "ConvertToNP(tofcal_branches,\"3\",\"Timing\",\"timing\",GEN3PathTiming,\"2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90f3d963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18104550\n",
      "Processing Chunk 1 out of 10\n",
      "Processing Chunk 2 out of 10\n",
      "Processing Chunk 3 out of 10\n",
      "Processing Chunk 4 out of 10\n",
      "Processing Chunk 5 out of 10\n",
      "Processing Chunk 6 out of 10\n",
      "Processing Chunk 7 out of 10\n",
      "Processing Chunk 8 out of 10\n",
      "Processing Chunk 9 out of 10\n",
      "Processing Chunk 10 out of 10\n"
     ]
    }
   ],
   "source": [
    "ConvertToNP(tofcal_branches,\"2\",\"Timing\",\"timingtest\",GEN2PathTiming,\"2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f35d3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30af7e70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1575666",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f418067",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Hodoscope\n",
    "ConvertToNP(hodo_branches,\"3\",\"HCal_data\",\"hodo\")\n",
    "\n",
    "#HCal\n",
    "ConvertToNP(hcal_branches,\"3\",\"HCal_data\",\"hcal\")\n",
    "\n",
    "#Trigger\n",
    "ConvertToNP(trigger_branches,\"3\",\"HCal_data\",\"trigger\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffc8bda",
   "metadata": {},
   "source": [
    "# Generic Pass1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e58ef87f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Chunk 1 out of 14\n",
      "Processing Chunk 2 out of 14\n",
      "Processing Chunk 3 out of 14\n",
      "Processing Chunk 4 out of 14\n",
      "Processing Chunk 5 out of 14\n",
      "Processing Chunk 6 out of 14\n",
      "Processing Chunk 7 out of 14\n",
      "Processing Chunk 8 out of 14\n",
      "Processing Chunk 9 out of 14\n",
      "Processing Chunk 10 out of 14\n",
      "Processing Chunk 11 out of 14\n",
      "Processing Chunk 12 out of 14\n",
      "Processing Chunk 13 out of 14\n",
      "Processing Chunk 14 out of 14\n"
     ]
    }
   ],
   "source": [
    "#Generic\n",
    "ConvertToNP(generic_branches,\"2\",\"He3\",\"generic\",GEN2Pathp1,\"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51c373a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Chunk 1 out of 13\n",
      "Processing Chunk 2 out of 13\n",
      "Processing Chunk 3 out of 13\n",
      "Processing Chunk 4 out of 13\n",
      "Processing Chunk 5 out of 13\n",
      "Processing Chunk 6 out of 13\n",
      "Processing Chunk 7 out of 13\n",
      "Processing Chunk 8 out of 13\n",
      "Processing Chunk 9 out of 13\n",
      "Processing Chunk 10 out of 13\n",
      "Processing Chunk 11 out of 13\n",
      "Processing Chunk 12 out of 13\n",
      "Processing Chunk 13 out of 13\n"
     ]
    }
   ],
   "source": [
    "#Generic\n",
    "ConvertToNP(generic_branches,\"3\",\"He3\",\"generic\",GEN3Pathp1,\"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9d5652b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Chunk 1 out of 5\n",
      "Processing Chunk 2 out of 5\n",
      "Processing Chunk 3 out of 5\n",
      "Processing Chunk 4 out of 5\n",
      "Processing Chunk 5 out of 5\n"
     ]
    }
   ],
   "source": [
    "#Generic\n",
    "ConvertToNP(generic_branches,\"4a\",\"He3\",\"generic\",GEN4aPathp1,\"1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c65034",
   "metadata": {},
   "source": [
    "# Generic Pass 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a95273ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35651630\n",
      "Processing Chunk 1 out of 18\n",
      "Processing Chunk 2 out of 18\n",
      "Processing Chunk 3 out of 18\n",
      "Processing Chunk 4 out of 18\n",
      "Processing Chunk 5 out of 18\n",
      "Processing Chunk 6 out of 18\n",
      "Processing Chunk 7 out of 18\n",
      "Processing Chunk 8 out of 18\n",
      "Processing Chunk 9 out of 18\n",
      "Processing Chunk 10 out of 18\n",
      "Processing Chunk 11 out of 18\n",
      "Processing Chunk 12 out of 18\n",
      "Processing Chunk 13 out of 18\n",
      "Processing Chunk 14 out of 18\n",
      "Processing Chunk 15 out of 18\n",
      "Processing Chunk 16 out of 18\n",
      "Processing Chunk 17 out of 18\n",
      "Processing Chunk 18 out of 18\n"
     ]
    }
   ],
   "source": [
    "#Generic\n",
    "ConvertToNP(generic_branchesp2,\"2\",\"He3\",\"generic\",GEN2Pathp2,\"2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81fde2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Chunk 1 out of 17\n",
      "Processing Chunk 2 out of 17\n",
      "Processing Chunk 3 out of 17\n",
      "Processing Chunk 4 out of 17\n",
      "Processing Chunk 5 out of 17\n",
      "Processing Chunk 6 out of 17\n",
      "Processing Chunk 7 out of 17\n",
      "Processing Chunk 8 out of 17\n",
      "Processing Chunk 9 out of 17\n",
      "Processing Chunk 10 out of 17\n",
      "Processing Chunk 11 out of 17\n",
      "Processing Chunk 12 out of 17\n",
      "Processing Chunk 13 out of 17\n",
      "Processing Chunk 14 out of 17\n",
      "Processing Chunk 15 out of 17\n",
      "Processing Chunk 16 out of 17\n",
      "Processing Chunk 17 out of 17\n"
     ]
    }
   ],
   "source": [
    "#Generic\n",
    "ConvertToNP(generic_branchesp2,\"3\",\"He3\",\"generic\",GEN3Pathp2,\"2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6e5e4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Chunk 1 out of 11\n",
      "Processing Chunk 2 out of 11\n",
      "Processing Chunk 3 out of 11\n",
      "Processing Chunk 4 out of 11\n",
      "Processing Chunk 5 out of 11\n",
      "Processing Chunk 6 out of 11\n",
      "Processing Chunk 7 out of 11\n",
      "Processing Chunk 8 out of 11\n",
      "Processing Chunk 9 out of 11\n",
      "Processing Chunk 10 out of 11\n",
      "Processing Chunk 11 out of 11\n"
     ]
    }
   ],
   "source": [
    "#Generic\n",
    "ConvertToNP(generic_branchesp2,\"4a\",\"He3\",\"generic\",GEN4aPathp2,\"2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8045721d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Chunk 1 out of 1\n"
     ]
    }
   ],
   "source": [
    "ConvertToNP(generic_branchesp2,\"4b\",\"He3\",\"generic\",GEN4bPathp2,\"2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aae3139d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Chunk 1 out of 4\n",
      "Processing Chunk 2 out of 4\n",
      "Processing Chunk 3 out of 4\n",
      "Processing Chunk 4 out of 4\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d065bd9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee06419",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#MachineLearning Data/ElasticSim/InelasticSim\n",
    "ConvertToNP(ml_branches,\"3\",\"HCal_data\",\"machinelearningD\")\n",
    "ConvertToNPSim(ml_branches,\"3\",\"HCal_data\",\"machinelearningES\")\n",
    "ConvertToNPInSim(ml_branches,\"3\",\"HCal_data\",\"machinelearningIS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58f70a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129704\n",
      "Processing Chunk 1 out of 1\n",
      "264763\n",
      "Processing Chunk 1 out of 1\n",
      "450806\n",
      "Processing Chunk 1 out of 1\n"
     ]
    }
   ],
   "source": [
    "#Simulation\n",
    "ConvertToNPSim(sim_branches,\"2\",\"simulation\")\n",
    "ConvertToNPSim(sim_branches,\"3\",\"simulation\")\n",
    "ConvertToNPSim(sim_branches,\"4\",\"simulation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13d1fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConvertToNPSim(sim_branches,\"2\",\"HCal_data\",\"simulation\",3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e11d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c0da258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "311751\n",
      "Processing Chunk 1 out of 1\n"
     ]
    }
   ],
   "source": [
    "#Simulation\n",
    "ConvertToNPInSim(insim_branches,\"3\",\"HCal_data\",\"insimulation\",GEN3InSim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55fcb27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
